{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "specialized_networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U9SBBLapSsj",
        "colab_type": "text"
      },
      "source": [
        "**Imports**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Wyup8IUtWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scipy.spatial import distance\n",
        "from scipy.special import softmax\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO3t9doLsx-M",
        "colab_type": "text"
      },
      "source": [
        "**Declaration of the Experiment class which includes methods for creating the neural networks, retrieving and pre-processing the dataset, and starting the experiment**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqzJHv04xkt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Experiment:\n",
        "\n",
        "\n",
        "  def __init__(self, learning_rate, num_classes, num_train_images_per_digit, num_test_images_per_digit, num_epochs):\n",
        "    self.dataset = self.load_dataset()\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_classes = num_classes\n",
        "    self.num_train_images_per_digit = num_train_images_per_digit\n",
        "    self.num_test_images_per_digit = num_test_images_per_digit\n",
        "    self.num_epochs = num_epochs\n",
        "\n",
        "\n",
        "  def shallow_autoencoder_model(self):\n",
        "    neural_net = Sequential()\n",
        "    neural_net.add(Flatten(input_shape = (28, 28)))\n",
        "    neural_net.add(Dense(784, activation='selu', bias_initializer=tf.constant_initializer(value=0.0), kernel_initializer=tf.constant_initializer(value=0.0)))\n",
        "    neural_net.add(Reshape((28, 28)))\n",
        "    neural_net.compile(optimizer='rmsprop', loss='mae', metrics=['accuracy'])\n",
        "    return neural_net\n",
        "\n",
        "\n",
        "  def conv_multi_classifier_model(self, learning_rate):\n",
        "\n",
        "    neural_net = Sequential()\n",
        "    \n",
        "    neural_net.add(Conv2D(64, activation='relu', input_shape=(28, 28, 1), kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    neural_net.add(BatchNormalization())\n",
        "    neural_net.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    neural_net.add(Flatten())\n",
        "\n",
        "    neural_net.add(Dense(128, activation='relu'))\n",
        "    neural_net.add(Dense(32, activation='relu'))\n",
        "    neural_net.add(Dense(10, activation='relu'))\n",
        "    neural_net.add(Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "    neural_net.compile(optimizer=Adam(lr=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return neural_net\n",
        "\n",
        "\n",
        "  def ff_multi_classifier_model(self, learning_rate):\n",
        "    neural_net = Sequential()\n",
        "    neural_net.add(Flatten(input_shape = (28, 28)))\n",
        "    neural_net.add(Dense(128, activation='relu'))\n",
        "    neural_net.add(Dense(32, activation='relu'))\n",
        "    neural_net.add(Dense(10, activation='relu'))\n",
        "    neural_net.add(Dense(self.num_classes, activation='softmax'))\n",
        "    neural_net.compile(optimizer=Adam(lr=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return neural_net\n",
        "\n",
        "\n",
        "  def load_dataset(self):\n",
        "    mnist_dataset = tf.keras.datasets.mnist.load_data()\n",
        "    (x_train, y_train) , (x_test, y_test) = mnist_dataset\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "    return (x_train, y_train) , (x_test, y_test)  \n",
        "\n",
        "\n",
        "  def pick_n_images_per_digit(self, num_images_per_digit=1, train=True):\n",
        "    train_data , test_data = self.dataset\n",
        "    picked_numbers = [0]*10\n",
        "    picked_data = []\n",
        "    if train:\n",
        "      data_used = train_data\n",
        "    else:\n",
        "      data_used = test_data\n",
        "    for x, y in zip(data_used[0], data_used[1]):\n",
        "      if picked_numbers[y] < num_images_per_digit:\n",
        "        picked_data.append((x, y))\n",
        "        picked_numbers[y] += 1\n",
        "        if len(picked_data) >= num_images_per_digit * 10:\n",
        "          break\n",
        "    return picked_data\n",
        "\n",
        "\n",
        "  def put_picked_data_in_bins(self, picked_data, train=True):\n",
        "    binned_picked_data = [[] for _ in range(10)]\n",
        "    for x, y in picked_data:\n",
        "      binned_picked_data[y].append((x, y))\n",
        "    if train:\n",
        "      self.picked_data = binned_picked_data\n",
        "    else:\n",
        "      self.picked_data_test = binned_picked_data\n",
        "    return binned_picked_data\n",
        "\n",
        "\n",
        "  def flatten_data(self, binned_data):\n",
        "    flat_data = []\n",
        "    for bin in binned_data:\n",
        "      for datum in bin:\n",
        "        flat_data.append(datum)\n",
        "    np.random.shuffle(flat_data)\n",
        "    return flat_data\n",
        "\n",
        "\n",
        "  def test_with_one_network(self, learning_rate, num_epochs, network_type='conv'):\n",
        "    picked_training_data = self.pick_n_images_per_digit(num_images_per_digit=self.num_train_images_per_digit, train=True)\n",
        "    binned_picked_training_data = self.put_picked_data_in_bins(picked_data=picked_training_data, train=True)\n",
        "    \n",
        "\n",
        "    picked_test_data = self.pick_n_images_per_digit(num_images_per_digit=self.num_test_images_per_digit, train=False)\n",
        "    binned_picked_test_data = self.put_picked_data_in_bins(picked_data=picked_test_data, train=False)\n",
        "    \n",
        "\n",
        "    binned_picked_training_data = binned_picked_training_data[:self.num_classes]\n",
        "    binned_picked_test_data = binned_picked_test_data[:self.num_classes]\n",
        "\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "\n",
        "    if network_type == 'conv':\n",
        "      classifier = self.conv_multi_classifier_model(learning_rate=learning_rate)\n",
        "    elif network_type == 'ff':\n",
        "      classifier = self.ff_multi_classifier_model(learning_rate=learning_rate)\n",
        "\n",
        "    for bin_index, training_bin in enumerate(binned_picked_training_data):\n",
        "        for training_datum in training_bin:\n",
        "          image, y_datum = training_datum\n",
        "          image = np.expand_dims(np.asarray(image), axis=2)\n",
        "          x_train.append(image)\n",
        "          y_train.append(y_datum)\n",
        "\n",
        "\n",
        "    for bin_index, test_bin in enumerate(binned_picked_test_data):\n",
        "        for test_datum in test_bin:\n",
        "          image, y_datum = test_datum\n",
        "          image = np.expand_dims(np.asarray(image), axis=2)\n",
        "          x_test.append(image)\n",
        "          y_test.append(y_datum)\n",
        "\n",
        "    print('Training The Traditional Network')\n",
        "    classifier.fit(np.asarray(x_train), np.asarray(y_train), batch_size=self.num_classes, epochs=num_epochs, verbose=0)\n",
        "    metrics = classifier.evaluate(np.asarray(x_test), np.asarray(y_test))\n",
        "    print('Accuracy With Traditional Network : %f' % metrics[1])\n",
        "    return metrics\n",
        "\n",
        "\n",
        "  def evaluate_test_data(self, test_data, classifiers):\n",
        "    correct = 0\n",
        "    encoders = classifiers\n",
        "    for x_test, y_test in test_data:\n",
        "      distances = []\n",
        "      for label, encoder in enumerate(encoders):\n",
        "        prediction = encoder.predict(np.asarray([np.expand_dims(x_test, axis=2)]))\n",
        "        dis = distance.euclidean(np.reshape(prediction[0], (1, 784)), np.reshape(x_test, (1, 784)))\n",
        "        distances.append(dis)\n",
        "      distances = softmax(distances)\n",
        "      #Uncomment to see an array of the reconstruction losses for each class\n",
        "      #print(distances)\n",
        "      predicted_label = np.argmin(distances)\n",
        "      if(predicted_label == y_test):\n",
        "        correct = correct + 1\n",
        "    return correct / len(test_data)  \n",
        "\n",
        "\n",
        "  def train_on_new_class(self, digit_data, encoders):\n",
        "\n",
        "    for index, (x_digit, y_digit) in enumerate(digit_data):\n",
        "      encoders[-1].fit(np.asarray(np.expand_dims([x_digit], axis=3)), np.asarray([x_digit]), batch_size=1, epochs=self.num_epochs, verbose=0)\n",
        "\n",
        "\n",
        "  def start(self):\n",
        "\n",
        "    picked_training_data = self.pick_n_images_per_digit(num_images_per_digit=self.num_train_images_per_digit, train=True)\n",
        "    binned_picked_training_data = self.put_picked_data_in_bins(picked_data=picked_training_data, train=True)\n",
        "    \n",
        "\n",
        "    picked_test_data = self.pick_n_images_per_digit(num_images_per_digit=self.num_test_images_per_digit, train=False)\n",
        "    binned_picked_test_data = self.put_picked_data_in_bins(picked_data=picked_test_data, train=False)\n",
        "\n",
        "    picked_digit = self.num_classes\n",
        "    binned_picked_digit_data = binned_picked_training_data[picked_digit]\n",
        "    binned_picked_test_digit_data = binned_picked_test_data[picked_digit]\n",
        "  \n",
        "    test_data_digit = binned_picked_test_data[:self.num_classes+1]\n",
        "    test_data_with_additional_class = self.flatten_data(test_data_digit)\n",
        "\n",
        "    binned_picked_training_data = binned_picked_training_data[:self.num_classes]\n",
        "    binned_picked_test_data = binned_picked_test_data[:self.num_classes]\n",
        "\n",
        "    test_data = self.flatten_data(binned_picked_test_data)\n",
        "\n",
        "    autoencoders = []\n",
        "\n",
        "    for i in range(self.num_classes):\n",
        "      autoencoders.append(self.shallow_autoencoder_model())\n",
        "      self.train_on_new_class(digit_data=binned_picked_training_data[i], encoders=autoencoders)\n",
        "\n",
        "      digit_accuracy = self.evaluate_test_data(binned_picked_test_data[i], autoencoders)\n",
        "      print('digit : %d , accuracy : %f' % (i, digit_accuracy))\n",
        "\n",
        "    accuracy = self.evaluate_test_data(test_data, autoencoders)\n",
        "    print('Accuracy of Specialized Networks Before Adding Class : %f' % accuracy)\n",
        "\n",
        "    \n",
        "    autoencoders.append(self.shallow_autoencoder_model())\n",
        "    self.train_on_new_class(digit_data=binned_picked_digit_data, encoders=autoencoders)\n",
        "\n",
        "    accuracy = self.evaluate_test_data(binned_picked_test_digit_data, autoencoders)\n",
        "    print('digit : %d , accuracy : %f' % (picked_digit, accuracy))\n",
        "\n",
        "    accuracy = self.evaluate_test_data(test_data_with_additional_class, autoencoders)\n",
        "    print('Accuracy of Specialized Networks After Adding Class : %f' % accuracy)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wLFTtWTqk8L",
        "colab_type": "text"
      },
      "source": [
        "**Calls To Start The Experiment**\n",
        "\n",
        "Options for network_type: 'conv' or 'ff'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwrUbP-oqrhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters of the experiment\n",
        "num_epochs = 10\n",
        "ipd = 10\n",
        "ipd_test = 10\n",
        "learning_rate_sp = 0.1\n",
        "learning_rate_trad = 0.001\n",
        "num_classes = 6\n",
        "\n",
        "# Instantiate the Experiment Class\n",
        "experiment = Experiment(\n",
        "                  learning_rate=learning_rate_sp,\n",
        "                  num_classes=6,\n",
        "                  num_train_images_per_digit=ipd,\n",
        "                  num_test_images_per_digit=ipd_test,\n",
        "                  num_epochs=num_epochs)\n",
        "#Start the experiment which trains the specialized networks and tests on them\n",
        "experiment.start()\n",
        "#Test on a traditional conv net or ff net.\n",
        "experiment.test_with_one_network(learning_rate_trad, num_epochs, network_type='conv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}